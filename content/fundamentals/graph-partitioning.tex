\section{Graph Embedding and Partitioning Techniques}
\label{sec:graph-partitioning-techniques}
The section \ref{subsec:StarSpace} introduced the embedding model StarSpace. The pre-trained StarSpace model predicts the vector for a given document. Moreover, this research employs StarSpace to partition the maintained bipartite graph by GraphJet on multiple instances. 


\emph{Graph Embedding} are related techniques to this thesis that use embedding approaches to partition graphs. This section will define explain in which fields graph embeddings can be used. It then discusses related work and the difference between them.


Graph embedding is an approach that transforms nodes, edges into vector spaces. Graph embedding frameworks use strategies to turn the graph into a computationally digestible format by reducing the dimensionality of the graph. The embedding of a graph can be used in different fields \cite{goyalGraphEmbeddingTechniques2018}, namely : 

\begin{enumerate}
    \item Node classification
    \item Link prediction
    \item Clustering and partitioning
    \item Visualization
\end{enumerate}


\emph{Graph partitioning} is used to put nodes based on their similarities in the same group (i.e., community). Partitioning a graph (also called community detection, or graph clustering) is a problem that has inspired multiple research efforts \cite{fortunatoCommunityDetectionGraphs2010}. They are various methods used to obtain graph partitioning. These methods can be categorized into three main groups \cite{goyalGraphEmbeddingTechniques2018}:

\begin{enumerate}
    \item Factorization
    \item Random Walk
    \item Deep Learning
\end{enumerate}


Factorization-based methods determine the connections between the nodes in a matrix and decompose this matrix to partition the graph. This can be archived with methods like Boolean matrix factorization \cite{miettinenModelOrderSelection2011}, which has been extended to streaming environments for biclustering bipartite graphs \cite{neumannBiclusteringBooleanMatrix2020}. Other approaches like \emph{HOPE} \cite{ouAsymmetricTransitivityPreserving2016b} use rely on other factorization methods, i.e., \emph{SVD} \cite{vanloanGeneralizingSingularValue1976} to generate the embeddings.


Random walk-based approaches generate embedding based on the similarity between the nodes. Embedding techniques like \emph{Deep Walk} \cite{perozziDeepWalkOnlineLearning2014} and \emph{node2vec} \cite{groverNode2vecScalableFeature2016} are used for graph representation.


More recent approaches like \cite{satuluriSimClustersCommunityBasedRepresentations2020} present a technique called \emph{Simclusters}. Instead of matrix factorization methods, the authors rely on a combination of similarity search and community discovery. The authors discuss that the calculation of the matrix factorization is not optimized for a massive scale. The authors propose a novel method to detect similar communities between users from the user-user bipartite graph to solve many personalization and recommendation problems at scale.


Recently deep learning has achieved great success in many classification applications. This can also be extended to graph classification and clustering. In \cite{tianLearningDeepRepresentations2014} they apply deep learning to learn the embeddings and run a \emph{k}-mean algorithm on the embedding to create the clusters. The semi-supervised node classification method proposed in \cite{kipfSemiSupervisedClassificationGraph2017} uses Graph convolutional networks (GCN) model to tackle this problem. 

Hybrid approaches introduced in \cite{yingGraphConvolutionalNeural2018}, called \emph{PinSage}. PinSage is an efficient random walk approach combined with graph convolutional neural networks (GCN) to generate embeddings of nodes.


The learnings from PinSage and Simclusters lead to the use of a hybrid method, combining GraphJet's SALSA algorithm with StarSpace. Rather than using a new random-walk approach of the discussed graph embedding techniques, we can apply GraphJet's random-walk algorithm (SALSA) to find similar documents (i.e., tweets) to each other. The SALSA algorithm can generate relevant documents for a given user. Finding relevant documents also applies to a given document. In other words, instead of starting from a user's vertex, the random walk initializes the walk from a document and locates similar documents to the starting node. This process continues for all the documents and creates an input file for the StarSpace model. The StarSpace model reads the generated documents and trains on them. With this approach, the StarSpace model can predict newly incoming documents vectors. By reducing the dimensions of these vectors, we can classify similar documents with each other and send them to a partition. 
