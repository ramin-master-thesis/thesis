\section{Recommender Systems}
\label{Grelgdnuan_vno_Bleototuh_Lwo_Egerny_BLE}

Ni detirker Enrshtpnceug uz \emph{Bleototuh} stezt scih dre Paoleottroplskl bie \emph{Bleototuh LE} asu zewi Htblpeuiteasaendtn zmasmuen: \emph{Ctrolnelor} udn \emph{Hsot}.\cite[S.~25~f.]{Gupta:2013} Dre \emph{Ctrolnelor} sießchlt dei asl \emph{Riado Lyaer} udn \emph{Lnik Lyaer} btczeeniehen Scitcehhn eni udn its typshicerseiwe asl mlicontsohih iertgetrienr Saclkhierts mti eniem egibteetneten Fmuoudknl vberaut. Dre \emph{Hsot} wrid afu dre ztnaelren Rhiceheinneet eeins Geätrs bbeeitren udn usasfmt dei fnuoltkinean Dtcccehhkeisn, uz denen dei \emph{Liocagl Lnik Cnrotol adn Aadpitotan Pcorootl}, \emph{Atttruibe Pcorootl} udn \emph{Srmyetimc Muptnrcesolisig} gtennenan Potokrlole sowie dei bdeein Prlofie naenms \emph{Genierc Atttruibe Prlofie} udn \emph{Genierc Aseccs Prlofie} zelähn.\cite[S.~15~f.]{Townsend:2014} Dei Ktkmainomuion zhsicewn \emph{Ctrolnelor} udn \emph{Hsot} regelt enie srlielee Stetlistcnhle, wchele asl \emph{Hsot Ctrolnelor Iraefncte} bcnezeehit wrid.\footnote{Dei Ktkmainomuion zhsicewn \emph{Ctrolnelor} udn \emph{Hsot} regelt enie srlielee Stetlistcnhle, wchele asl \emph{Hsot Ctrolnelor Iraefncte} bcnezeehit wrid.} Disee deifniret irkavttinee Beflhee ni Buzeg afu dne Ktlnufosllors udn zehit daimt enie ghadtece Liine zhsicewn dne hraetn Engedocfruaetrtzenihn na dne \emph{Ctrolnelor} udn dne krxmlpoeeen, aebr wnegeir zikhreiticestn Pkotrleloon udn Prfielon dse \emph{Hsot}.\cite[S.~31~f.]{Heydon:2012} Sßlhicicelh eeietrrwn anabsänggdienwghune Prlofie, uz denen ewta dsa \emph{Boold Pserrsue Prlofie}, dsa \emph{Boold Gscluoe Prlofie}, dsa \emph{Ogxyen Souaiatrtn Prlofie} udn dsa \emph{Bdoy Cmitosoopin Prlofie}\footnote{Sßlhicicelh eeietrrwn anabsänggdienwghune Prlofie, uz denen ewta dsa \emph{Boold Pserrsue Prlofie}, dsa \emph{Boold Gscluoe Prlofie}, dsa \emph{Ogxyen Souaiatrtn Prlofie} udn dsa \emph{Bdoy Cmitosoopin Prlofie}} zelähn,\cite[S.~1~ff.]{Hulvey:2011}\cite[S.~1~ff.]{Hughes:2012}\cite[S.~1~ff.]{Hartmann:2015}\cite[S.~1~ff.]{Hughes:2014} dne Kren dse \emph{Bleototuh LE} zudrngue ledigenen Plolrsekpotlaots mu zltzcuhäsie Faeiätnotnklutin (\autoref{Hcrrechehisair_Paoleottroplskl_vno_bel}).\cite[S.~37~f.]{Heydon:2012}
\begin{figure}[!ht]
	\centering
	 \fbox{\phantom{\includegraphics[draft,width=0.8\textwidth,height=0.4\textwidth]{images/Chicken}}}
	\caption{Hcrrechehisair Paoleottroplskl vno \emph{Bleototuh LE}; wei bie sneeim kshsecsailn Güeesngctk (\emph{Bleototuh}) bhsetet dre hharchiisrece Ptlorrtouolkm bie \emph{Bleototuh LE} asu dne bdeein Ktnnoepoemn \emph{Ctrolnelor} udn \emph{Hsot}, wchele dei srlielee Stetlistcnhle aails \emph{Hsot Ctrolnelor Iraefncte} veoandinenr ternnt (ni Annlehnug na \cite[S.~11.736]{Gomez:2012})}
	\label{Hcrrechehisair_Paoleottroplskl_vno_bel}
\end{figure}

\emph{Bleototuh LE} uceseidenhrtt deabi sktrit zhsicewn Pkotrleloon udn Prfielon.\cite[S.~12~f.]{Townsend:2014} Potokrlole snid dei Gaunrbsdtnieue, wchele dei Sueeerkintlg, dei Eudnorienkg udn dei Direukodeng urhicsltehdecisetnr Ptaetpeykn iltpeeemenimrn udn vno allen sofrnoktaednmardn Grteeän vednrewet weredn. Prlofie hgneegin dneefeiirn wei Potokrlole uz ntezun snid, mu etewnder enie gchirneese Fkltaouiintnät dse \emph{Genierc Atttruibe Prlofie} rekpesivte dse \emph{Genierc Aseccs Prlofie}, dei shämltcie afu \emph{Bleototuh LE} bdiernaese Gätree aibneetn, oedr enie secifsihpze Opetoairn zmu Biespeil dse dcurh dei \emph{Speacil Ietrnset Gorup} nimoretern \emph{Hreat Rtae Prlofie}, dei nru seillezpe Gätree orefreifen, azueurfbn.\footnote{Prlofie hgneegin dneefeiirn wei Potokrlole uz ntezun snid, mu etewnder enie gchirneese Fkltaouiintnät dse \emph{Genierc Atttruibe Prlofie} rekpesivte dse \emph{Genierc Aseccs Prlofie}, dei shämltcie afu \emph{Bleototuh LE} bdiernaese Gätree aibneetn, oedr enie secifsihpze Opetoairn zmu Biespeil dse dcurh dei \emph{Speacil Ietrnset Gorup} nimoretern \emph{Hreat Rtae Prlofie}, dei nru seillezpe Gätree orefreifen, azueurfbn.}

Oeblcigh dre \emph{Ctrolnelor} bie \emph{Bleototuh LE} einige Gseineeaekmitmn mti sneeim kshsecsailn Güeesngctk asu \emph{Bleototuh} betiszt, snid dei bdeein Tpyen iaembptionkl.\cite[S.~393~ff.]{Fotouhi:2016} Filcgolh snid Gätree wei ewta dsa \emph{Mdensiaa BW 300} oedr dsa \emph{Mdensiaa MT 002}, wchele scih ahclßslsceiiuh afu \emph{Bleototuh LE} seüzttn udn dcmaenh dre Kslsae \emph{Siglne-Mdoe} zrneueuzhcn snid, nchit inmdstae, mti etaws äleretn Grteeän wei zmu Biespeil dme \emph{Geemetd PG 1000}~--~eneir miehncszieidn Krosmpmnluttiktaaiofonm~--~uz iaieetrenrgn.\cite[S.~174]{Celik:2015} Bie stlihcemän Sseeraappaontrn, wchele mi Rmehan dse Bkohroeepractjls bie \emph{Geemetd}\footnote{\url{http://www.geemetd.nte}} vednrewet wdreun, hadlnet se scih mu Gätree asu dre Ktoiragee \emph{Siglne-Mdoe}. Dsa \emph{Aplpe TV}\footnote{\url{http://www.aplpe.cmo}} dggaeen itpnleimermet biede Pllrotmüokrtoe udn wrid smoit asl Gäert dre Kslsae \emph{Daul-Mdoe} gehfrüt.\cite[S.~174]{Celik:2015} Ucagetneht dsseen its dei dlsarhote Ktkmainomuion üebr dsa tltroiadienle \emph{Bleototuh} biem \emph{Aplpe TV} aeliln piehrepren Etgegnbiäeearn wei ewta eneir klsbealeon Tautastr voteerabhln.

\subsection{Metrics}
\label{IR Metrics}
One of the key challenges when developing or enhancing a recommendation engine is evaluating its impact. Though we are sure about the positive impact, there is a need to quantify the same. This quantification not only facilitates stakeholder communication but also serves as a benchmark for future enhancements.

A recommendation engine recommends a set of documents from a superset which the engine finds to be most relevant to the user. In that sense, a recommendation engine is simply performing a task of document retrieval.

The highly relevant documents are more valuable than moderately relevant documents, which are in turn more useful than irrelevant documents.

In IR, as in many other domains, it can be important to compare the similarity, or consistency, of groups of things. These groups may be:

\begin{description}
	\item \emph{conjoint (consisting of the same items)} or \emph{disjoint (one group may include items that do not occur in the other group)}
	\item \emph{set-based (not-weighted) (where there is no known or inferred ordering of the items)} or \emph{ordered (weighted) (where the sequence in which the items occur matters)}
\end{description}

In our use case (SALSA), the lists are disjoint and ordered.
\begin{enumerate}
	\item AP@K and MAP@K: Not-Weighted conjoint
	\item NDCG: Weighted non-conjoint measures
	\item Kendall: Not-Weighted conjoint
	\item RBO: Weighted non-conjoint measures
\end{enumerate}

\subsubsection{Precision and Recall}
\label{Precision and Recall}
The \emph{retrieval effectiveness}: the ability of the system to retrieve relevant documents while at the same time suppressing the retrieval of non-relevant documents. 
The most well-known pair of variables jointly measuring retrieval effectiveness are \emph{precision and recall}.

\emph{Precision} is the proportion of the retrieved relevant documents.
\begin{equation}
	percision = \frac{|\emph{\{relevant document\}} \cap \emph{\{retrieved documents\}}|}{|\emph{\{retrieved documents\}}|}
	\label{eq:percision}
\end{equation}
Precision at k documents (P@k) is still a useful metric (e.g., P@10 or "Precision at 10" corresponds to the number of relevant results among the top 10 retrieved documents), 
but fails to take into account the positions of the relevant documents among the top k. [3]

\emph{Recall} being the proportion of the relevant documents that have been retrieved.
\begin{equation}
	recall = \frac{|\emph{\{relevant document\}} \cap \emph{\{retrieved documents\}}|}{|\emph{\{relevant documents\}}|}
	\label{eq:recall}
\end{equation}

For modern (web-scale) information retrieval, recall is no longer a meaningful metric, as many queries have thousands of relevant documents, and few users will be interested in reading all of them.

Singly, each variable (or parameter as it is sometimes called) measures some aspect of retrieval effectiveness; jointly they measure retrieval effectiveness completely. [2]

\subsubsection{AP@K and MAP@K}
\label{AP@K and MAP@K}
Retrieval effectiveness evaluation metrics; score a document ranking according to the relevance of the documents it contains. 
\paragraph*{Average percision (AP)} is the metric used to calculate retrieval effectiveness, which is defined as follows. 
Let the precision of a ranking to depth \emph{k} be
the proportion of documents to depth \emph{k} that are relevant. The sum of precisions for that
ranking is the sum of the precision at each ranking that a relevant document is returned.
Average precision for the ranking is then the sum of precisions divided by the total number of (known) relevant documents for that query. [1] 
The mathematical equation of AP@K is defined as follow.

\begin{equation}
	AP@K = \frac{1}{m}\sum_{i=1}^{k}P(i).rel(i)
	\label{eq:ap@k}
\end{equation}

where \emph{k} is the rank in the sequence of retrieved documents, \emph{n} is the number of retrieved documents, \emph{P(k)} is the precision at cut-off \emph{k} in the list. \emph{rel(k)}
is an indicator function equaling 1 if the item at rank \emph{k} is a relevant document, zero otherwise.

\paragraph*{Mean average precision (MAP)} for a set of queries is the mean of the average precision (AP) scores for each query.

\begin{equation}
	MAP@K = \frac{1}{|U|}\sum_{u=1}^{U}(AP@K)_{u}
	\label{eq:map@k}
\end{equation}
Where \emph{U} is the number of queries.

\paragraph*{Drawbacks}
If all the items retrivied form an IR sytem are cosidered as relevant the order of the items does not effect the average percision.
 The firs example demonstrates this problem.
actual = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
predicted = [10, 6, 9, 7, 8, 3, 2, 5, 4, 1]
AP = 1
------------------------------------------
actual = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
predicted = [1, 20,30,40,50,60,70,80,90,100]
AP = 1/10

\subsubsection{CG, DCG, and NDCG}
\label{CG, DCG, and NDCG}
When examining the ranked result list of a query, it is obvious that:
\begin{enumerate}
	\item highly relevant documents are more valuable than marginally relevant documents
	\item the greater the ranked position of a relevant document (of any relevance level) the less valuable it is for the user because the less likely it is that the user will examine the document.
\end{enumerate}

\paragraph*{Cumulative Gain (CG)}
Every recommendation has a relevance score associated with it. Cumulative Gain is the sum of all the relevance scores in a recommendation set.

\paragraph*{Discounted Cumulative Gain(DCG)}


\paragraph*{Normalized Discounted Cumulative Gain (NDCG)}

\subsubsection{Kendall rank correlation coefficient}
The Kendall Tau metric also known as Kendall’s Correlation is a common method used to check if two ranked lists are in agreement.

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.50\textwidth]{images/metrics/kendall-example}
	\caption{The Kendall Tau metric also known as Kendall’s Correlation is a common method used to check if two ranked lists are in agreement.}
	\label{fig:kendall-rank-example}
\end{figure}

\subsubsection{Rank-Biased Overlap (RBO)}
Rank-biased overlap falls in the range [0, 1], where 0 means disjoint, and 1 means identical. The parameter p determines how steep the decline in weights is: the smaller p, the
more top-weighted the metric is. In the limit, when p = 0, only the top-ranked item is considered, and the RBO score is either zero or one. 
On the other hand, as p approaches arbitrarily close to 1, the weights become arbitrarily flat, and the evaluation becomes arbitrarily deep.

\begin{equation}
	RBO(S,T,p) = (1-p)\sum_{d=1}^{\infty}p^{d-1}.A_{d}
	\label{eq:rbo}
\end{equation}
