\chapter{Conclusion and Future Work}
\label{chap:conclusion}
This work introduces a partitioning technique, which learns the dependency of the data based on the input and output of systems and enables distribution. The researched method uses an embedding model to spread text document data on various shared-nothing instances (workers) based on their semantic similarity. The content-based partitioning idea proposed in this work is prototyped on a recommender system called GraphJet. In the distributed environment, each instance consists of the simplified storage engine, recommendation engine, and the API endpoint module of GraphJet. Each worker's recommendation results are merged to a single ranked list of items using innovative data fusion techniques introduced in this thesis. This research studies and measures the various test scenarios using the proposed evaluation pipeline.


It is evident that the recommendation quality drops if a worker obtains a fraction of the data. Specifically for the GraphJet use case, the main goal is to suggest recommendations in a multi-partition environment as identical to the single instance recommendations. The results of the experiments (with 500 sampled users in a two-partition environment) show that the proposed approach (StarSpace Most Interactions) outperforms the random partitioning method (Murmur2 Union Results), with retrieval effectiveness of almost 53\% compared to 38\%. It is noticeable that the performance of StarSpace Most Interactions cannot be considered ideal with retrieval effectiveness of 53\%. On the other hand, the comparison between the single instance and the baseline achieved 63\%, denoting the non-deterministic behavior of the random walk algorithm in producing recommendations.


Additionally, assuming that all the items not included in the baseline are irrelevant made the evaluation strict and resulted in low retrieval effectiveness. Some of these items, which are not included in the baseline, might still interest the user. Moreover, using the Mean Average Precision (MAP) as the primary metric to evaluate the results does not provide enough evidence of whether the results got better or worse. The metric fails to measure if the irrelevant data (i.e., the items that are not in the baseline) are of interest to the user. Therefore, no definite conclusion can be drawn as to whether the multi-partition environment necessarily suggests irrelevant recommendations for a user. 


In practice, recommendation data consists of user feedback, which can be gathered with a user study. The Web UI described in section \ref{sec:web-ui} show more promising outcomes for a user, although further  user studies are needed to provide more evidence. 


Despite the limitations, these are valuable findings showing that the proposed partitioner surpasses the random partition method: First, the Most Interactions data fusion approach performs well with StarSpace partitioning. StarSpace partitions the data with respect to the relationship between them, and when a user has a higher degree inside that partition (i.e., more interaction with documents in that partition), it is also likely that this user has more interest in the documents (i.e., tweets) from that partition. 


Second, the Union Results (also Highest Hit) method relies on the hit number for choosing the recommendations. However, the hit number is heavily dependant on the amount of data on each partition. A more sparse partition outputs more significant hit counts since the possibility that the random walk algorithm visits a node more often increases. Thus, the hit count will mislead the algorithm to choose current recommendations, which can be seen when comparing the results when using Murmur2 hash partitioning. The Murmur2 Union Results delivers a MAP@10 value of 40\%, whereas the Murmur2 Highest Hit only yields MAP@10 value of 27\%. Yet, the Union Results method works better on Murmur2 and performs worse on StarSpace because Murmur2 distributes the data more uniformly across the partitions than StarSpace.


The findings also indicate that the partitioning of the data affects the recommendation generation time. When partitioning the data on multiple workers, the data each worker holds reduces respectively. Through this data reduction, each worker has fewer indices, which results in a sparse bipartite graph. Therefore, the random-walk algorithm can retrieve the adjacency lists from an index more quickly.


This thesis joins a growing corpus of research showing that latency improvements and possibly even recommendation improvements can be achieved through content-based partitioning.


Considering the above, additional research needs to be conducted to overcome the limitations and improve the performance. The following three ideas are proposed for future studies:

\begin{enumerate}
    \item The Load Balancer proposed in section \ref{sec:load-balancing} provides a good starting point for discussion and further research. After implementing the load balancer, the overall performance should be evaluated. Further research can be undertaken by measuring the overhead added by the load balancer during partitioning.
    
    \item The ideas presented in the section \ref{sec:other-use-cases} presents two new use cases where the primary research approach of this work can be adopted. Future investigations are necessary to validate the concepts described.
    
    \item The crawled dataset from Twitter misses feedback data on the produced recommendation. Having no feedback on the generated recommendations makes it challenging to distinguish if the yield items are relevant or not. The relevancy of an item affects the overall evaluation result. Therefore, this research assumes that all the results that are not included in the baseline are non-relevant items for the assessment. This assumption limits the evaluation. Future reaches can develop and study other datasets with feedback or investigate new evaluation approaches like user testing to evaluate such systems. The Web UI Dashboard introduced in section \ref{sec:web-ui} is a good starting point for further investigations and designing user testing to evaluate the recommendation quality.
    
    \item Future research could continue to explore the continued learning of the embedding model, where the model learns from the incoming data and can adapt itself even more to the changes. 
\end{enumerate}