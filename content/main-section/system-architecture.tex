\section{System Architecture}
\label{sec:system-architecture}

This research implements and simulates the GraphJet architecture to evaluate and test the proposed approach of data partitioning. As explained in section \ref{sec:GraphJet}, GraphJet architecture consists of three main layers: a storage engine, a recommendation engine, and an API endpoint layer. The same layer system inspires this work's architecture. 


This section goes through the prototyped system architecture and the design decisions taken. The first subsection explains the single instance architecture and the functionality of each layer. Afterwards, the next subsection describes the distributed architecture of the system. The implemented prototype can be found in the repository\footnote{\url{https://github.com/ramin-master-thesis/D-Salsa}}.


\subsection{Single Machine}
\label{subsec:single-machine}
The high-level architecture of a single instance can be seen in figure \ref{fig:single-machine-architecture}. The worker (i.e., instance) receives an input query (i.e., user-ID) and then yields a ranked list of recommendations (i.e., tweets). The detailed single instance architecture demonstrating each layer is shown in figure \ref{fig:single-machine-architecture-detailed}. In the following, each section describes each component of the system and explains how each layer works.

\begin{figure}[!htb]
    \centering
    \begin{subfigure}[b]{0.75\textwidth}
       \includegraphics[width=1\linewidth]{images/simple-worker}
       \caption{Single machine high level overview}
       \label{fig:single-machine-architecture} 
    \end{subfigure}
    
    \begin{subfigure}[b]{0.8\textwidth}
       \includegraphics[width=1\linewidth]{images/simple-worker-detailed}
       \caption{Single machine including each layer}
       \label{fig:single-machine-architecture-detailed}
    \end{subfigure}
    
    \caption {The architecture of a single worker, (a) Receives a query when new recommendations are requested. It also ingests incoming documents. (b) More detailed view of each layer of a single worker. The layers consist of a Storage (i.e., Indexer) engine, a recommendation engine, and an API endpoint. The storage layer receives the incoming document and creates the left and right indices. The API endpoint layer receives the read queries and forwards them to the recommendation layer.}
\end{figure}


\subsubsection{Storage Layer}
\label{subsub:storage-index-layer}
The storage layer is responsible for maintaining the bipartite graph in memory. A bipartite graph is a graph whose vertices can be split into two disjoint and independent sets U and V such that every edge connects a vertex in U to one in V \cite{walkerImplementingDiscreteMathematics1992}. The two disjoint sets of U and V can be built using two indices. In other words, the bipartite graph consists of two indices: left side index, right side index. For the specific user-tweet bipartite graph, one index stores all tweets for a specific user. The other index stores all users for a particular tweet.

GraphJet uses mutable (hot) and immutable (cold) index segments to store the bipartite graph \cite{sharmaGraphJetRealtimeContent2016}. With this approach, GraphJet optimizes newly incoming edge insertion. This research assumes that the system is not receiving any new edges during its runtime. To keep the indexing as simple as possible, a \emph{simple index} system is used. This approach uses a single vertex-ID (i.e., node-ID) as its index key. The index key points to an adjacency list containing the node-IDs that the index key interacts with. Table \ref{tab:simple-indexing} illustrates a small example of this indexing system. The node-ID 5 has interactions with node-IDs 200 and 50. To summarize, the left index of the user-tweet bipartite graph uses the user-IDs as its key and the tweet-IDs as the adjacency list values and vice versa.


This thesis also introduces a third index. The content of the tweets is also crawled and later used for partitioning purposes. An index between the tweet-ID and the content is created to retrieve the content of a given tweet-ID. This index generates a \emph{Content Graph}.

\begin{table}[!htb]
    \centering
    \caption{Simple indexing example}
    \label{tab:simple-indexing}
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Key} & \textbf{Adjacency List} \\
        \hline
        5 & [200, 50] \\
        \hline
        12 & [60, 170, 88] \\
        \hline
        ... & ... \\
        \hline
    \end{tabular}
\end{table}


\subsubsection{Recommendation Layer}
\label{subsubsec:recommendation-layer}
The recommendation layer implements the SALSA \cite{lempelSALSAStochasticApproach2001} algorithm. The recommendation layer needs multiple configuration parameters to initialize the random walk. These parameters are described in table \ref{tab:salsa-parameters}. Throughout this research and evaluation, the parameters are kept constant. Considering SALSA a black box is generally sufficient to produce good results for the assessment.



\begin{table}[!htb]
    \centering
    \caption{SALSA algorithm parameters}
    \label{tab:salsa-parameters}
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Parameter} & \textbf{Description} \\
        \hline
        Root node & ID of the starting node \\
        \hline
        Limit & Number of items to return \\
        \hline
        Walks & Number of random SALSA walks \\
        \hline
        Walks length & Length of the walks \\
        \hline
        Reset probability & Probability to start from the root node \\
        \hline
        Indexer & An implementation of the indexer module \\
        \hline
    \end{tabular}
\end{table}


The recommendation layer interacts with both the indexer and the API endpoint. The API endpoint layer calls the recommender layer and injects the necessary parameters to start the random walk. As explained before, the indexer builds two indices: left side index and right side index. The algorithm needs to ask each index side to perform the walk on the bipartite graph. The recommender calls the left side index from the indexer to receive the adjacency list and then chooses one ID randomly. After selecting the node-ID, a visit count of that node-ID is incremented and stored. The walk continues by asking the right side index for the next adjacency list. This process continues until the number of walks reaches its limit. Finally, the recommender sorts the visited nodes by their visit count and cut-offs the returned with respect to the cut-off limit set in the configuration file.


According to the main paper of GraphJet, the random walk always starts from a vertex located on the left index \cite{sharmaGraphJetRealtimeContent2016}. In other words, for the GraphJet use case, the SALSA algorithm starts from the requested user-ID node on the left index and then walks to the tweet-ID on the right index. This thesis extends the SALSA algorithm. Instead of starting from the left side, the algorithm initiates from a vertex on the right side. The output is a ranked list of right-side vertices (i.e., tweet-IDs). With this approach, the random walk produces relevant items to the initial vertex. This method is used to create training data for the StarSpace model (see section \ref{subsec:generating-training-data}).

\subsubsection{API Endpoint Layer}
\label{subsubsec:api-endpoint-layer}
The API endpoint layer provides an interface to interact with the system. The API endpoint layer interacts with the recommendation layer and receives the list of recommendations. This module converts the ranked list to a JSON format and sends them back to the user.
The API endpoint also interacts with the index layer to gather information. This information consist of:

\begin{enumerate}
    \item Degree number of a particular node in the graph
    \item Total number of vertices in the left and right index
    \item Total number of edges in the left and right index
\end{enumerate}

\subsection{Multiple Machines}
\label{subsec:multiple-machines}
This section explains the multi-instance architecture. Each instance (i.e., worker) consists of a single machine, explained in the previous subsection. Each worker receives an identifier (partition-ID) at deployment time in the cluster. Each data entity gets a partition-ID through the \emph{partitioner} module and lands on the desired partition. Figure \ref{fig:multiple-machine-architecture-write} visualizes this process. The partitioner module is explained in section \ref{sec:partitioning}. After the data is spread across the workers, the system is ready to receive the read queries. 


Figure \ref{fig:multiple-machine-architecture-read} shows what happens when a read query is sent. The query (i.e., user-ID) is forwarded to all the workers. If the user-ID exists in the left index of the worker, the worker will start the random-walk algorithm. Each worker then sends their list of recommendations to the \emph{Data Fusion} module. This module, depending on the method chosen(explained in section \ref{sec:data-fusion-approaches}), will then generate a single list of recommendations and yield it to the given user.



\begin{figure}[!htb]
    \centering
    \begin{subfigure}[b]{0.75\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{images/multi-partition-workers-write}
        \caption{Multiple instance environment during write time}
        \label{fig:multiple-machine-architecture-write}
    \end{subfigure}
    
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{images/multi-partition-workers-read}
        \caption{Multiple instance environment during read time}
        \label{fig:multiple-machine-architecture-read}
    \end{subfigure}
    
    \caption {The shared-nothing multiple instance environment with three workers. (a) visualizes the partitioning process. Whenever a new document is received, the partitioner will compute its partition-ID and send it to a worker. The shape between the partitioner and the workers indicates an exclusive gateway (XOR) that the partitioner will choose only one worker. (b) Showing the multiple instance environment after the data partitioning has finished and the system is ready to receive read queries. Each worker runs the SALSA algorithm in complete isolation and forwards its results to the data fusion module. Based on the method chosen, the data fusion module yields a single ranked list of recommendations.}
\end{figure}
