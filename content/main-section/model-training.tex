\section{Model Training}
\label{sec:model-training}
Section \ref{subsec:StarSpace} explained that the StarSpace model learns the mapping between documents it was trained on. We can define "similar" documents to each other for the StarSpace model and train the model based on that data. The trained model then reads the content of newly arrived documents and computes the embedding vector. 


For example the trained model receives new documents three documents: \emph{D$_1$, D$_2$}, and \emph{D$_3$}. Imagine that the first two documents are related to each other. The trained model calculates the embedding vector of these three documents. Since \emph{D$_1$} and \emph{D$_2$} are similar to each other, their distance in the so-called embedding space would be smaller to each other. Respectively, the \emph{D$_3$} would be distant to two other documents in this space.


As explained in the section \ref{subsec:partitioning-star-space} to calculate the partition-ID, the StarSpace model also needs a projection matrix to reduce the dimensions of the predicted embedding vector. Figure \ref{fig:star-space-training} shows the flowchart of the training and projection matrix calculation process.


In the beginning, related documents are generated in a format that the StarSpace model can digest. The generated data is then used to train the model with the configured parameters. After the training process is finished, the projection matrix is calculated and saved for later use. In the following sections, each step of the flowchart \ref{fig:star-space-training} is explained in detail.

\begin{figure}[!htb]
    \centering
    \includegraphics[height=0.75\textwidth]{images/train-StarSpace-flow-chart}
    \caption{Flowchart of the training process. It starts with the data generation for the model training and continues with the PCA and projection matrix calculation.}
    \label{fig:star-space-training}
\end{figure}

\subsection{Generating Training Data}
\label{subsec:generating-training-data}
The training data needs to be generated so that semantically related documents (i.e., tweets) would land next to each other in the training file that the StarSpace model consumes. The following will describe the process of how the training data is generated.

The SALSA algorithm can produce relevant recommendations for a given user. Perciecly, for a given node on the left index side, a list of relevant nodes on the right side index is suggested. The idea of finding relevant documents for a user can be applied to documents as well. In other words, the SALSA algorithm initiates the random walk from the right index side (tweet side) and returns the right side nodes (tweets). Finally, putting these tweets together will create a group (entity) of semantically similar tweets to each other. This group of similar tweets can then be used to train the StarSpace model.


The training data algorithm initially loads all the identifiers from the right side index (tweet-IDs). Then for each tweet-ID, the SALSA random walk is executed. The algorithm outputs ten relevant documents for a given tweet-ID. Afterwards, from the identifier-content index (see section \ref{subsub:storage-index-layer}), the content of the suggested tweet-IDs along with queried tweet-ID are retrieved and joined together into a tab-separated string format. The algorithm continues until all the identifiers in the list extend and saves the results in a text file.
semantical

To speed up the computation time, we can argue that the training data generation is a map operation and can be run in parallel for each document separately.


To illustrate how well the SALSA algorithm generates relevant tweets, consider the following example:
The tweet \texttt{"Live views of Starship SN8’s flight test -> https://t.co/Hs5C53qBxb https://t.co/OvAloTO6UQ"} written by the \emph{SpaceX} Twitter account is sent. Table \ref{tab:example-train-data} shows the generated results. By observing the results, you can see how diverse the content of these tweets is. One result contains chemical equations, and another one agrees with Elon Musk. Thus, the topic of the initial tweet is somehow relevant to the output tweets.

\begin{table}[!htb]
    \centering
    \caption{Example output of similar tweets for training data generation}
    \label{tab:example-train-data}
    \begin{tabular}{|m{0.95\textwidth}|}
        \hline
        \textbf{Recommendations} \\
        \hline
        Welcome to Mars, @NASAPersevere! Congratulations @NASA and @NASAJPL – another successful mission to the Red Planet https://t.co/EtVb2f2C5I \\
        \hline
        Tesla’s bold "yoke" steering system is legal on UK roads, confirms regulators \\
        \hline
        @Erdayastronaut @ErcXspace Short-term, CH4 delivered \& O2 produced. Propellant is ~78\% O2. Long-term, Sabatier reaction to convert CO2 + H2O -> CH4 + O2 using wind \& solar power. \\
        \hline
        @elonmusk Well done @elonmusk and the team, keep pushing those boundaries and ignore the competition,  you have enough vision to see the finish line whilst they are struggling to find the start! (Remember 2MWs ultracapacitor in the frunk option for 100\% regen in any temp and the win!) \\
        \hline
        @elonmusk @NASASpaceflight 250 tons would be nice and easy for even engine scaling , since you are using odd-numbered the goal has to be 333 tons \\
        \hline
        @Erdayastronaut Great footage Tim and the team. The audio was great also,  the kids were covering their ears during launch!! \\
        \hline
        @elonmusk @Teslarati Totally agree, the new Lotus ev has additional active damping for longitudinal acceleration as well... \\
        \hline
        Feel your pain @SpaceX , it's only 5 year old homebrew but I shall name it SN1 https://t.co/1sf1MzXaH3 \\
        \hline
        \#LaunchThePengwing The naughty Elves are not clear of the pad! Thank you Felix and team. https://t.co/UF7FB8P4OL \\
        \hline
        @elonmusk Totally agree \\
        \hline
    \end{tabular}
\end{table}


\subsection{Projection Matrix Calculation}
\label{subsec:projection-matrix-calculation}
Following the flowchart in figure \ref{fig:star-space-training}, after the training data is generated, the StarSpace model is ready for the training. After the model training finishes and the model is saved to disk, the projection matrix calculation starts. The projection matrix is calculated for a trained model individually. In other words, the projection matrix should be recomputed whenever a new model is trained.


This computation is done by predicting the embedding vector of each sentence in the training dataset using the trained StarSpace model. Then calculating the eigenvector and eigenvalues and sort these pairs in descending order in a matrix. For more details on how mathematically the projection matrix is calculated, please refer to the main paper of PCA \cite{woldPrincipalComponentAnalysis1987}.


The instance running the calculation needs to have enough memory to simultaneously load the training dataset and the StarSpace model. The training dataset used in this work is almost 3~GB, and the StarSpace model can reach a size up to 13~GB. So the projection matrix computation needs at least 16~GB of memory to get initialized. Besides, the calculation itself is also memory-consuming since, for all the values in the training dataset, the eigenpairs (eigenvalue and eigenvector) need to be kept in memory.


Key findings emerge from the massive StarSpace model size: The model's size depends on the dataset it was trained with. The model creates a mapping for each unique word it sees during train time. The dataset used in this work is directly crawled from Twitter without going through any data cleansing process. The dataset contains Twitter-ID, emojis, and URLs, which enlarge the model mapping that the model creates for the words. Besides, the tweets are in multiple languages, which adds even more words to the model mapping.


Techniques like data cleansing (like removing the Twitter-IDs, emojis, and URLs) can be applied to reduce the dataset and the model's size. Moreover, the dataset can be separated based on the languages, and each model can be trained for a language separately. These improvements can be considered as future work.


\subsection{Hyperparameter Tuning}
\label{subsec:hyperparameter-tuning}
The model of StarSpace has multiple hyperparameters that control the learning process of the model. The complete documentation of parameters can be found in the StarSpace repository on GitHub\footnote{\url{https://github.com/facebookresearch/StarSpace\#full-documentation-of-parameters}}. 


The implication is that changing the model parameters will affect two essential aspects of this reach: First, how the data gets distributed on the partitions (i.e., workers). In other words, how balanced the partitions get. Second, the recommendation quality. Since each model computes different embedding vectors for a document, this will determine which partition the document eventually lands. Such effects can not be found in methods like Murmur2 hash since this method computes the hash of a given identifier with a consistent mathematical approach. This work implemented a hyperparameter tuning platform to train different models and compare their learning quality.


Table \ref{tab:hyperparameter} shows different parameters values used to train the StarSpace model. Combining these parameters variations will train 16 different models. Selecting the best model for content-based partitioning can be done over two criteria: First would be the recommendation quality. Second, the data distribution and how well balanced each partition is. Both of these topics are evaluated and discussed in the section \ref{subsubsec:eval-hyperparameter}.


\begin{table}[!htb]
    \centering
    \caption{Configuration parameters}
    \label{tab:hyperparameter}
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Parameter} & \textbf{Values} \\
        \hline
        Learning rate & [0.01, 0.05] \\
        \hline
        Size (dimension) of embedding vectors & [100, 300] \\
        \hline
        Dropout probability for RHS features & [0.5, 0.8] \\
        \hline
        Text normalization for input file & [True, False]\\
        \hline
    \end{tabular}
\end{table}
