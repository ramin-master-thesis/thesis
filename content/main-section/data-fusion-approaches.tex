\section{Data Fusion Approaches}
\label{sec:data-fusion-approaches}
The section \ref{subsec:data-fusion} introduced multiple data fusion architecture patterns based on the system architecture and the algorithm used. This work's data fusion algorithms are inspired by the Single Formulation Multiple Schemes (SFMS) pattern. 

Section \ref{subsec:GraphJet-Recommendation-Engine} explained how the SALSA algorithm operates. The algorithm keeps track of how many times it visits a vertex during the random walk. This visit count is defined as the \emph{Hit} count of a node. The algorithm sorts the items in descending order when the random walk finishes based on their hit count. The proposed approaches in the following section mainly use the hit number to unify the data together. This section discusses why only using the hit number comes with its downside when sorting or picking the results.


This section of this thesis introduces and explains three data fusion approaches that the data fusion component (demonstrated in section \ref{subsec:multiple-machines}) uses to generate the single ranked list of recommendations. These three approaches are:

\begin{enumerate}
    \item Union Results
    \item Highest Hit
    \item Most Interactions
\end{enumerate}

\subsection{Union Results}
\label{subsec:data-fusion-union-results}
The implication that the SALSA algorithm uses the hit count as criteria to choose the items for a given user brings up the idea to use the hit count to pick the best results of different partitions.
In this approach, the results of each partition get merged first and then based on their hit count, the results get sorted, and the top \emph{K} elements are taken. Figure \ref{fig:data-fusion-union-results} demonstrates this process with an example. The first document-ID belongs to partition zero, and the two following ones belong to partition one. Practically, this approach is unifying items from each partition with the greatest hit count. The benchmarks of this data fusion technique can be found in section \ref{subsubsec:eval-data-fusion}. 


\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.8\textwidth]{images/data-fusion-union-results}
    \caption{Data fusion using the union results}
    \label{fig:data-fusion-union-results}
\end{figure}

\subsection{Highest Hit}
\label{subsec:data-fusion-highest-hit}
This technique also uses the hit count as the main choose criteria. The \emph{Highest Hit} approach chooses the results from a partition with the greates hit count. The intution here is that the partition with the greates hit count might contain the best results.


Figure \ref{fig:data-fusion-highest-hit} visualizes this process clearly. The first partition (partition zero) has a higher hit count compared to the second partition (134 versus 99). Therefore all the results of the first partition are chosen as the end result.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.8\textwidth]{images/data-fusion-highest-hit}
    \caption{Data fusion using the highest hit that a partition contains}
    \label{fig:data-fusion-highest-hit}
\end{figure}

\subsection{Most Interactions}
\label{subsec:data-fusion-most-interactions}
The last approach is based on user interactions and their interests. After segmenting the data using the StarSpace model, we can argue that if users have a more significant node degree on a particular partition, their interests are on that partition.


Figure \ref{fig:data-fusion-highest-ineterest} explains this partitioning technique clearly. The user interacted with five documents. The first four documents the user interacted with have similar topics, colored in yellow, and one (colored in red) has a completely different subject. The four documents land on the first partition and the other document in the other partition. After computing the recommendations for the given user on each partition, the data fusion module retrieves the node degree of the user on each partition. The partition where the user has the most interactions (i.e., the partition holding the biggest node degree) is the chosen candidate. For this particular example, partition zero's recommendations are picked.


Another aspect that \ref{fig:data-fusion-highest-ineterest} denotes is that if a user interacts with documents that are relevant to each other, the possibility that this user might like documents in the same topic arises. With this technique, we select recommendations that the user is the most interested in. 


\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.85\textwidth]{images/data-fusion-highest-interest}
    \caption{Visualization of StarSpace partitioning technique. This approach distributes the documents based on their topic. In this particular example, the user interacted with five documents. The StarSpace model detects that four of them are relevant to each other. Therefore, these four documents land on the same partition. The \emph{Most Interactions} data fusion approach chooses the generated recommendations of partition zero.}
    \label{fig:data-fusion-highest-ineterest}
\end{figure}


This approach is entirely independent of the hit number that the random walk of SALSA generates. Observing the output data and their hit counts denotes that the amount of data on a partition affects the hit count. This means if a partition has a dense graph with many vertices, the hit numbers will be lower compared to a partition maintaining a spares graph. This is because the possibility of returning to a node already visited reduces for a dense graph.


The first two data fusion approaches work best with partitioning methods that keep a balanced data distribution on each partition (like Murmur2). The third approach focuses more on the interest and content of the documents, making them more suitable for the StarSpace partitioning method. The detailed evaluation of different data fusion approaches is discussed in \ref{subsubsec:eval-data-fusion}.

